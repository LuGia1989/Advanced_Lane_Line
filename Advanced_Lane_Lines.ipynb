{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import neccessary package\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Camera Calibration and Image Undistortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# function to calibration the vehicle camera\n",
    "def camera_calibration(image_directory, cal_image):\n",
    "    objp = np.zeros((6 * 9, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "    objpoints = []  # 3d points in real world space\n",
    "    imgpoints = []  # 2d points in image plane.\n",
    "    images = glob.glob(image_directory)\n",
    "\n",
    "    # loop over each image in the image_directory\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9, 6), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(img, (9, 6), corners, ret)\n",
    "            cv2.imshow('img', img)\n",
    "            cv2.waitKey(500)\n",
    "\n",
    "    # Do camera calibration on a given test image\n",
    "    img = cv2.imread(cal_image)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "    # Save the camera calibration result (mtx, dist) in the dictionary for late use\n",
    "    dist_pickle = {}\n",
    "    dist_pickle['mtx'] = mtx\n",
    "    dist_pickle['dist'] = dist\n",
    "    pickle.dump(dist_pickle, open('camera_cal.p', 'wb'))\n",
    "    #plt.show()\n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# After calibration the vehicle camera, use this function to undistort images\n",
    "def undistortion (image, pickle_file, print_flag = None, image_directory = None, cal_image = None):\n",
    "    # check to see if the pickle_file already existed, then load camera calibration parameters \n",
    "    if os.path.isfile(pickle_file):\n",
    "        dist_pickle = pickle.load(open(pickle_file, 'rb'))\n",
    "        mtx = dist_pickle['mtx']\n",
    "        dist = dist_pickle['dist']\n",
    "    else:\n",
    "        # if there is no pickle_file, do the camera calibration\n",
    "        mtx, dist = camera_calibration(image_directory,cal_image)\n",
    "    img = cv2.imread(image)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # write a undistorted image on a file\n",
    "    cv2.imwrite('output_images/undistored_image.jpg', dst)\n",
    "\n",
    "    if print_flag == 'yes':\n",
    "        # Visualize undistortion\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        ax1.imshow(img, cmap='gray')\n",
    "        ax1.set_title('Original Image', fontsize=10)\n",
    "        ax2.imshow(dst, cmap='gray')\n",
    "        ax2.set_title('Undistorted Image', fontsize=10)\n",
    "        plt.show()\n",
    "    return dst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# camera calibration\n",
    "# image_directory = 'camera_cal/*.jpg'\n",
    "# cal_image = 'camera_cal/calibration4.jpg'\n",
    "# mtx, dist = camera_calibration(image_directory,cal_image)\n",
    "\n",
    "# Undistort the test image\n",
    "test_image = 'test_images/test6.jpg'\n",
    "pickle_file = 'camera_cal.p'\n",
    "dst = undistortion(test_image,pickle_file, print_flag= 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Gradient and Color Threshold\n",
    "### (a). Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function to threshold an image for a given range and Sobel kernel\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi / 2)):\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # use bilateral filter to filter out noises while preserve edges of images\n",
    "    gray = cv2.bilateralFilter(gray,5,9,9)\n",
    "\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    # Take the absolute value of the gradient direction,\n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_direction = np.zeros_like(absgraddir)\n",
    "    binary_direction[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_direction\n",
    "\n",
    "\n",
    "# Define a sobel function that takes an image, gradient orientation,\n",
    "# and threshold min / max values.\n",
    "def apply_sobel (image, orient='x', sobel_threshmin = 0, sobel_threshmax = 100, sobel_kernel = 3):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # use bilateral filter to filter out noises while preserve edges of images\n",
    "    gray = cv2.bilateralFilter(gray,5,9,9)\n",
    "\n",
    "    # Depend on the given orientation, select the right orient\n",
    "    if orient == 'x':\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize= sobel_kernel)\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        scaled_sobelx = np.uint8(255 * abs_sobelx / np.max(abs_sobelx))\n",
    "        scaled_sobel = scaled_sobelx\n",
    "\n",
    "    elif orient == 'y':\n",
    "        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize= sobel_kernel)\n",
    "        abs_sobely = np.absolute(sobely)\n",
    "        scaled_sobely = np.uint8(255 * abs_sobely / np.max(abs_sobely))\n",
    "        scaled_sobel = scaled_sobely\n",
    "\n",
    "    sobel_binary = np.zeros_like(scaled_sobel)\n",
    "    sobel_binary[(scaled_sobel >= sobel_threshmin) & (scaled_sobel <= sobel_threshmax)] = 1\n",
    "    return sobel_binary\n",
    "\n",
    "# Define a function to return the magnitude of the gradient\n",
    "# for a given sobel kernel size and threshold values\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # use bilateral filter to filter out noises while preserve edges of images\n",
    "    gray = cv2.bilateralFilter(gray,5,9,9)\n",
    "\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255\n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8)\n",
    "\n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    return mag_binary\n",
    "\n",
    "# Define a function to return the color threshold for a given S-channel of HLS color space\n",
    "def apply_hls_color_threshold (image, hls_threshmin=0, hls_threshmax=100):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    # use bilateral filter to filter out noises while preserve edges of images\n",
    "    hls = cv2.bilateralFilter(hls,5,9,9)\n",
    "    h = hls[:,:,0]\n",
    "    l = hls[:,:,1]\n",
    "    s = hls[:,:,2]\n",
    "    hls_binary = np.zeros_like(s)\n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    hls_binary[(s > hls_threshmin) & (s <= hls_threshmax)] = 1\n",
    "    return  hls_binary\n",
    "\n",
    "# Define a function to return the color threshold for a given S-channel of HSV color space\n",
    "def apply_hsv_color_threshold (image, hsv_threshmin=0, hsv_threshmax=100):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    # use bilateral filter to filter out noises while preserve edges of images\n",
    "    hsv = cv2.bilateralFilter(hsv,5,9,9)\n",
    "    h = hsv[:,:,0]\n",
    "    s = hsv[:,:,1]\n",
    "    v = hsv[:,:,2]\n",
    "    hsv_binary = np.zeros_like(s)\n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    hsv_binary[(s > hsv_threshmin) & (s <= hsv_threshmax)] = 1\n",
    "    return hsv_binary\n",
    "\n",
    "# Define a function to combine different binary images\n",
    "def combined_threshold (image, print_flag = None):\n",
    "    # Define the region of interest so that later will be use to  mask out\n",
    "    # the texture inside the lane.\n",
    "    img_size = np.shape(image)\n",
    "    halfTop = np.uint(img_size[0] / 1.5)\n",
    "    halfBottom = np.uint(img_size[0])\n",
    "    center = np.uint(img_size[1] / 2)\n",
    "    TopLeft = np.uint(center - 0.05 * (img_size[1] / 2))\n",
    "    TopRight = np.uint(center + 0.05 * (img_size[1] / 2))\n",
    "    BottomLeft = np.uint(center - 0.5 * (img_size[1] / 2))\n",
    "    BottomRight = np.uint(center + 0.7 * (img_size[1] / 2))\n",
    "    src = np.float32([[TopLeft, halfTop], [TopRight, halfTop], [BottomRight, halfBottom], [BottomLeft, halfBottom]])\n",
    "    \n",
    "    sobelx_binary = apply_sobel(image, 'x', sobel_threshmin=20, sobel_threshmax=100, sobel_kernel=3)\n",
    "    sobely_binary = apply_sobel(image, 'y', sobel_threshmin=20, sobel_threshmax=100, sobel_kernel=3)\n",
    "    direction_binary = dir_threshold(image,sobel_kernel=3, thresh=(0.7, 1.3))\n",
    "    hls_binary = apply_hls_color_threshold(image,hls_threshmin=180, hls_threshmax=255)\n",
    "    hsv_binary = apply_hsv_color_threshold(image, hsv_threshmin=180, hsv_threshmax=255)\n",
    "    mag_binary = mag_thresh(image,sobel_kernel=3,mag_thresh=(50,255))\n",
    "\n",
    "    combined_sobelx_hls_binary = np.zeros_like(sobelx_binary)\n",
    "    #combined_sobelx_hls_binary[(sobelx_binary == 1) | (hls_binary == 1)] = 1\n",
    "    combined_sobelx_hls_binary[(sobelx_binary == 1 | ((mag_binary == 1) & (direction_binary == 1))) | hls_binary == 1] = 1\n",
    "\n",
    "    # mask out texture inside the lane\n",
    "    cv2.fillPoly(combined_sobelx_hls_binary, np.array([src], np.int32), 0)\n",
    "    \n",
    "    # plot 6 different gradient and color threshold technique on a given test image\n",
    "    if print_flag == 'yes':\n",
    "        plt.figure('Test Images', figsize=(20,10))\n",
    "        plt.subplot(2,3,1)\n",
    "        plt.title('sobel x image')\n",
    "        plt.imshow(sobelx_binary, cmap='gray')\n",
    "\n",
    "        plt.subplot(2, 3, 2)\n",
    "        plt.title('sobel y image')\n",
    "        plt.imshow(sobely_binary, cmap='gray')\n",
    "\n",
    "        plt.subplot(2, 3, 3)\n",
    "        plt.title('sobel direction')\n",
    "        plt.imshow(direction_binary, cmap='gray')\n",
    "\n",
    "        plt.subplot(2, 3, 4)\n",
    "        plt.title('hls threshold image')\n",
    "        plt.imshow(hls_binary, cmap='gray')\n",
    "\n",
    "        plt.subplot(2, 3, 5)\n",
    "        plt.title('hsv threshold image')\n",
    "        plt.imshow(hsv_binary, cmap='gray')\n",
    "\n",
    "        plt.subplot(2, 3, 6)\n",
    "        plt.title('combined sobelx and hls image')\n",
    "        plt.imshow(combined_sobelx_hls_binary, cmap='gray')\n",
    "        plt.show()\n",
    "    return combined_sobelx_hls_binary, sobelx_binary, mag_binary, direction_binary, hls_binary\n",
    "\n",
    "# Define a function to apply the combined gradient and color threshold technique on eight\n",
    "# test images in the test_image_directory\n",
    "def test_image_binaries(test_image_directory, pickle_file):\n",
    "    list_combined_binary = []\n",
    "    images = glob.glob(test_image_directory)\n",
    "    for i, image in enumerate(images):\n",
    "        dst = undistortion(image,pickle_file, print_flag = None)\n",
    "        combined_sobelx_hls_binary, sobelx_binary, mag_binary, direction_binary, hls_binary \\\n",
    "        = combined_threshold(dst)\n",
    "        list_combined_binary.append(combined_sobelx_hls_binary)\n",
    "        plt.figure('Eight Test Images', figsize=(20,10))\n",
    "        plt.subplot(2,4, i+1)\n",
    "        plt.title('Image: test%s.jpg'%str(i+1))\n",
    "        plt.imshow(combined_sobelx_hls_binary, cmap='gray')\n",
    "    plt.show()\n",
    "    return list_combined_binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (b). Gradient and Color Threshold Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Apply gradient and color threshold on the test image\n",
    "combined_sobelx_hls_binary = combined_threshold(dst, print_flag='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Apply combined gradient and color threshold on different images\n",
    "test_image_directory = 'test_images/*.jpg'\n",
    "list_combined_binary = test_image_binaries(test_image_directory,pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a region of interest of lane line to apply perspective transform\n",
    "def boundRectangle(image):\n",
    "    # Define a region of interest of lane line to apply perspective transform\n",
    "    img_size = np.shape(image)\n",
    "    halfTop = np.uint(img_size[0] / 1.5)\n",
    "    halfBottom = np.uint(img_size[0])\n",
    "    center = np.uint(img_size[1] / 2)\n",
    "    TopLeft = np.uint(center - 0.15 * (img_size[1] / 2))\n",
    "    TopRight = np.uint(center + 0.25 * (img_size[1] / 2))\n",
    "    BottomLeft = np.uint(center - 0.9 * (img_size[1] / 2))\n",
    "    BottomRight = np.uint(center + 1.1 * (img_size[1] / 2))\n",
    "    cv2.line(image,(TopLeft,halfTop),(TopRight, halfTop),(0,255,0),2)\n",
    "    cv2.line(image, (TopRight, halfTop), (BottomRight, halfBottom), (0, 255, 0), 6)\n",
    "    cv2.line(image, (BottomRight, halfBottom), (BottomLeft, halfBottom), (0, 255, 0), 6)\n",
    "    cv2.line(image, (BottomLeft, halfBottom), (TopLeft, halfTop), (0, 255, 0), 6)\n",
    "\n",
    "    # Choose the four points for source and destination to apply perspective transform\n",
    "    src = np.float32([[TopLeft, halfTop], [TopRight, halfTop], [BottomRight, halfBottom], [BottomLeft, halfBottom]])\n",
    "    dst = np.float32([[0, 0], [img_size[1], 0], [img_size[1], img_size[0]], [0, img_size[0]]])\n",
    "\n",
    "    return src,dst, image\n",
    "\n",
    "# Define a perspective transform to warp images in bird-eye view, and plot them\n",
    "def perspective_transform(image, print_flag = None, figsize = None):\n",
    "    src, dst, img = boundRectangle(image)\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(image, M, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    unwarped = cv2.warpPerspective(warped, M_inv, (warped.shape[1], warped.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Visualize\n",
    "    if print_flag == 'yes':\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.title('Original binary')\n",
    "        plt.imshow(img, cmap='gray')\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title('bird-eye view')\n",
    "        plt.imshow(warped, cmap='gray')\n",
    "        plt.show()\n",
    "    return warped, M, unwarped, M_inv\n",
    "\n",
    "# Define a function to plot bird-eye view for a list of images\n",
    "def bird_eye_view (list_combined_binary, figsize=None):\n",
    "    for image in list_combined_binary:\n",
    "        warped = perspective_transform(image,print_flag='yes', figsize=figsize)\n",
    "        cv2.waitKey(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Draw a region of interest box and warp the test image for bird-eye view\n",
    "warped = perspective_transform(dst, print_flag='yes', figsize=(20,40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bird-view of the 8 test images in the test_image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bird_eye_view(list_combined_binary, figsize=(8,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4. Finding Lane\n",
    "### (a). Calculate Lane Line, Lane Curvature and vehicle position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function to calculate lane line\n",
    "def Advanced_Lane_Line(binary_warped):\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[np.uint(binary_warped.shape[0] // 2):, :], axis=0)\n",
    "    \n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = (np.dstack((binary_warped, binary_warped, binary_warped)) * 255).astype('uint8')\n",
    "    \n",
    "    #Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0] / 2)\n",
    "    leftx_base = np.argmax(histogram[100:midpoint]) + 100\n",
    "    rightx_base = np.argmax(histogram[midpoint:-100]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0] / nwindows)\n",
    "\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 70\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 70\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = binary_warped.shape[0] - window * window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img, (win_xleft_low, win_y_low), (win_xleft_high, win_y_high), (0, 255, 0), 2)\n",
    "        cv2.rectangle(out_img, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (0, 255, 0), 2)\n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (\n",
    "            nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (\n",
    "            nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Return a dictionary of relevant variables\n",
    "    lane_map = {}\n",
    "    lane_map['left_fit'] = left_fit\n",
    "    lane_map['right_fit'] = right_fit\n",
    "    lane_map['nonzerox'] = nonzerox\n",
    "    lane_map['nonzeroy'] = nonzeroy\n",
    "    lane_map['out_img'] = out_img\n",
    "    lane_map['left_lane_inds'] = left_lane_inds\n",
    "    lane_map['right_lane_inds'] = right_lane_inds\n",
    "    return lane_map\n",
    "\n",
    "# Define a function to calculate a lane curvature\n",
    "def calculate_lane_curve(lane_map):\n",
    "    # Extract relevant variables from lane_map dictionary\n",
    "    nonzerox = lane_map['nonzerox']\n",
    "    nonzeroy = lane_map['nonzeroy']\n",
    "    left_lane_inds = lane_map['left_lane_inds']\n",
    "    right_lane_inds = lane_map['right_lane_inds']\n",
    "\n",
    "    y_eval = 719\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 15 / 720  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7 / 900  # meters per pixel in x dimension\n",
    "\n",
    "    # Extract left and right pixel  positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2 * left_fit_cr[0] * y_eval * ym_per_pix + left_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
    "        2 * left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2 * right_fit_cr[0] * y_eval * ym_per_pix + right_fit_cr[1]) ** 2) ** 1.5) / np.absolute(\n",
    "        2 * right_fit_cr[0])\n",
    "\n",
    "    # print('left curve: ', left_curverad, ' ,right curve:  ', right_curverad)\n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "# Define a function to calculate lane curvature and vehicle offset\n",
    "def calculate_vehicle_position(image, lane_map):\n",
    "    # Calculate vehicle offset from lane center, in meters\n",
    "    left_fit = lane_map['left_fit']\n",
    "    right_fit = lane_map['right_fit']\n",
    "    \n",
    "    # Calculate vehicle center offset in pixels\n",
    "    bottom_y = image.shape[0] - 1\n",
    "    bottom_x_left = left_fit[0] * (bottom_y ** 2) + left_fit[1] * bottom_y + left_fit[2]\n",
    "    bottom_x_right = right_fit[0] * (bottom_y ** 2) + right_fit[1] * bottom_y + right_fit[2]\n",
    "    vehicle_position = image.shape[1] / 2 - (bottom_x_left + bottom_x_right) / 2\n",
    "\n",
    "    # Convert pixel offset to meters\n",
    "    xm_per_pix = 3.7 / 700  # meters per pixel in x dimension\n",
    "    vehicle_position *= xm_per_pix\n",
    "    # print('vehicle position: ', vehicle_position)\n",
    "    return vehicle_position\n",
    "\n",
    "# Define a function to draw color map on lane\n",
    "def drawing(undist, left_fit, right_fit, m_inv, left_curve, right_curve, vehicle_position):\n",
    "    # Define the y-points to draw color map\n",
    "    ploty = np.linspace(0, undist.shape[0] - 1, undist.shape[0])\n",
    "    \n",
    "    # Fit the left and right lane in second order polynomial curve\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "    \n",
    "    # Define color warp to draw color map on lane lines\n",
    "    color_warp = np.zeros((720, 1280, 3), dtype='uint8')\n",
    "    \n",
    "    # Find the point coordinates on left and right lanes\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Color fill with yellow for coordinate points\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (255, 255, 0))\n",
    "    \n",
    "    # Unwarp back to the original images\n",
    "    newwarp = cv2.warpPerspective(color_warp, m_inv, (undist.shape[1], undist.shape[0]))\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    \n",
    "    # Calculate the lane curvature and vehicle offset\n",
    "    avg_curve = (left_curve + right_curve) / 2\n",
    "    label_str = 'Radius of curvature: %.1f m' % avg_curve\n",
    "    result = cv2.putText(result, label_str, (30, 40), 0, 1, (0, 0, 0), 3, cv2.FONT_HERSHEY_DUPLEX)\n",
    "    label_str = 'Vehicle offset from lane center: %.3f m' % vehicle_position\n",
    "    result = cv2.putText(result, label_str, (30, 70), 0, 1, (0, 0, 0), 3, cv2.FONT_HERSHEY_DUPLEX)\n",
    "    plt.imshow(result)\n",
    "    plt.show()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (b) Bird-vew with lane finding drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function to visualize birdeye view with rectangle boxes\n",
    "def birdview_rectangle_visualization(binary_warped, lane_map):\n",
    "    # Extract relevant variables from lane_map dictionary\n",
    "    left_fit = lane_map['left_fit']\n",
    "    right_fit = lane_map['right_fit']\n",
    "    nonzerox = lane_map['nonzerox']\n",
    "    nonzeroy = lane_map['nonzeroy']\n",
    "    out_img = lane_map['out_img']\n",
    "    left_lane_inds = lane_map['left_lane_inds']\n",
    "    right_lane_inds = lane_map['right_lane_inds']\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0] - 1, binary_warped.shape[0])\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    plt.imshow(out_img)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    plt.show()\n",
    "\n",
    "# Define a function to visualize birdeye view with window search area\n",
    "def birdview_visualization(binary_warped, lane_map):\n",
    "    left_fit = lane_map['left_fit']\n",
    "    right_fit = lane_map['right_fit']\n",
    "    nonzerox = lane_map['nonzerox']\n",
    "    nonzeroy = lane_map['nonzeroy']\n",
    "    left_lane_inds = lane_map['left_lane_inds']\n",
    "    right_lane_inds = lane_map['right_lane_inds']\n",
    "\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped)) * 255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0] - 1, binary_warped.shape[0])\n",
    "    left_fitx = left_fit[0] * ploty ** 2 + left_fit[1] * ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0] * ploty ** 2 + right_fit[1] * ploty + right_fit[2]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    margin = 70\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx - margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx + margin, ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx - margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx + margin, ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0, 255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0, 255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    plt.imshow(result)\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)\n",
    "    plt.show()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (c). Process images to find lane line and perform visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function to annotate the input image with lane line detection and markings\n",
    "def process_image(img_in):\n",
    "    #Annotate the input image with lane line markings\n",
    "    #Returns annotated image\n",
    "\n",
    "    global mtx, dist\n",
    "\n",
    "    # Undistort, threshold, perspective transform\n",
    "    undist = cv2.undistort(img_in, mtx, dist, None, mtx)\n",
    "    img, abs_bin, mag_bin, dir_bin, hls_bin = combined_threshold(undist)\n",
    "    binary_warped, binary_unwarped, m, m_inv = perspective_transform(img)\n",
    "\n",
    "    lane_map = Advanced_Lane_Line(binary_warped)\n",
    "    left_fit = lane_map['left_fit']\n",
    "    right_fit = lane_map['right_fit']\n",
    "    left_curve, right_curve = calculate_lane_curve(lane_map)\n",
    "    vehicle_position = calculate_vehicle_position(undist, lane_map)\n",
    "\n",
    "    # Perform final visualization on top of original undistorted image\n",
    "    # birdview_rectangle_visualization(binary_warped, lane_map)\n",
    "    # birdeyeview = birdview_visualization(binary_warped, lane_map)\n",
    "    result = drawing(undist, left_fit, right_fit, m_inv, left_curve, right_curve, vehicle_position)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function to display the lane search window in birdeye-view mode\n",
    "def process_birdeyeview(img_in):\n",
    "\n",
    "    global mtx, dist\n",
    "\n",
    "    # Undistort, threshold, perspective transform\n",
    "    undist = cv2.undistort(img_in, mtx, dist, None, mtx)\n",
    "    img, abs_bin, mag_bin, dir_bin, hls_bin = combined_threshold(undist)\n",
    "    \n",
    "    # warp the combined gradient/color threshold image\n",
    "    binary_warped, binary_unwarped, m, m_inv = perspective_transform(img)\n",
    "    \n",
    "    # warp the undistortion image\n",
    "    warped, unwarped, m, m_inv = perspective_transform(undist)\n",
    "\n",
    "    lane_map = Advanced_Lane_Line(binary_warped)\n",
    "    left_fit = lane_map['left_fit']\n",
    "    right_fit = lane_map['right_fit']\n",
    "    binary_warped = birdview_visualization(binary_warped, lane_map)\n",
    "    \n",
    "    return warped, binary_warped, lane_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function to display lane curvature and vehicle offset on image\n",
    "def text_curvature_offset(img, view, lane_map):\n",
    "    # Calculate the lane curvature and vehicle offset\n",
    "    left_curve, right_curve = calculate_lane_curve(lane_map)\n",
    "    vehicle_position = calculate_vehicle_position(img, lane_map)\n",
    "    \n",
    "    # Calculate the average curvature \n",
    "    avg_curve = (left_curve + right_curve) / 2\n",
    "    label_str = 'Radius of curvature: %.1f m' % avg_curve\n",
    "    view = cv2.putText(view, label_str, (30, 40), 0, 1, (255, 255, 255), 6, cv2.FONT_HERSHEY_DUPLEX)\n",
    "    label_str = 'Vehicle offset from lane center: %.3f m' % vehicle_position\n",
    "    view = cv2.putText(view, label_str, (30, 70), 0, 1, (255, 255, 255), 6, cv2.FONT_HERSHEY_DUPLEX)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    return view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function to display combined_threshold images\n",
    "def process_combined_thresh(img_in):\n",
    "    #Annotate the input image with lane line markings\n",
    "    #Returns annotated image\n",
    "\n",
    "    global mtx, dist\n",
    "\n",
    "    # Undistort, threshold, perspective transform\n",
    "    undist = cv2.undistort(img_in, mtx, dist, None, mtx)\n",
    "    img, abs_bin, mag_bin, dir_bin, hls_bin = combined_threshold(undist)\n",
    "    img_out = (np.dstack((img, img, img)) * 255).astype('uint8')\n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a function to display multiview of lane tracking in a full HD.\n",
    "def multiview(img_in):\n",
    "    # Define the main view in full HD.\n",
    "    view = np.zeros((1080, 1920, 3), dtype=np.uint8)\n",
    "    result = process_image(img_in)\n",
    "    \n",
    "    # warp image to birdeye-view\n",
    "    warped, binary_warped, lane_map = process_birdeyeview(img_in)\n",
    "    \n",
    "    # Define the position of the lane tracking on the main view\n",
    "    view[0:720, 0:1280] = result\n",
    "    \n",
    "    # Define the position of the birdeye-view image on the main view\n",
    "    view[0:330, 1300:1900] = cv2.resize(warped, (600,330),interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Define the position of the birdeye-view of the combined gradient/color threshold image on the main\n",
    "    # view\n",
    "    view[370:700, 1300:1900] = cv2.resize(binary_warped,(600,330), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Define the position to display curvature and vehicle offset information\n",
    "    view[750: 1000, 0:800] = text_curvature_offset(binary_warped, view[750: 1000, 0:800], lane_map)\n",
    "    \n",
    "    #Define the position to display combined threshold images\n",
    "    combined_thresh = process_combined_thresh(img_in)\n",
    "    view[750:998, 840:1280] = cv2.resize(combined_thresh, (440, 248), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dist_pickle = pickle.load(open(pickle_file,'rb'))\n",
    "mtx = dist_pickle['mtx']\n",
    "dist = dist_pickle['dist']\n",
    "img_file = 'test_images/test6.jpg'\n",
    "img = mpimg.imread(img_file)\n",
    "result = process_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_video(input_file, output_file):\n",
    "    #Given input_file video, save annotated video to output_file\n",
    "    video = VideoFileClip(input_file)\n",
    "    #annotated_video = video.fl_image(process_image)\n",
    "    #annotated_video = video.fl_image(process_birdeyeview)\n",
    "    annotated_video = video.fl_image(multiview)\n",
    "    annotated_video.write_videofile(output_file, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "process_video('project_video.mp4', 'submit_multiview_with_displayInfo.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
